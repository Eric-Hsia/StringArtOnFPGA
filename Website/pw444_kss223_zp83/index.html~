<!DOCTYPE html>
<html>
	<head> <title> ECE 5760 Final Project </title> </head>
	<body>
		<style>
.flex-container {
	display: flex;
	justify-content: center;
	align-items: center;
}
figure figcaption {
	text-align: center;
	font-weight: bold;
}
table, th, td {
	border: 1px solid black;
	border-collapse: collapse;
	text-align: center;
	padding: 5px;
}
		</style>

		<h1>ECE 5760 Final Project: String Art on FPGA</h1>
		<h3> Peng Wu (pw444), Kowin Shi (kss223), Zhizhong Peng (zp83) </h3>
		<br>
		<h2>Introduction </h2>
		<p> Our final project was inspired by a hardware invention posted on the fantastic Youtube channel <a href = https://www.youtube.com/watch?v=M1gXuKFspgY>Barton Dring</a>, in which he built a fully automated machine to manufacture circular framed "string art" pieces from a continuous thread, that look just like the rendering shown below.</p>
		<div class="flex-container">
			<figure>
				<img src="./Images/einstein_ori.png" alt="Original Image" style="width:300px">
				<figcaption>Fig.1 Original Image</figcaption>
			</figure>
			<figure>
				<img src="./Images/einstein_ex.png" alt="Processed Image" style="width:300px">
				<figcaption>Fig.2 MATLAB Generated String Art Image</figcaption>
			</figure>
		</div>
		<p> The algorithm that Barton used to derive the processed images was developed by computer graphics researchers at TU Wien (Vienna University of Technology), which is outlined in detail in this <a href = https://www.cg.tuwien.ac.at/research/publications/2018/Birsak2018-SA/>paper</a>. In it, they formulate the problem mathematically and present their trials of different optimization methods to approach a good result, which in the end is judged subjectively by the human eye (as art should be, although they do present quantitative evaluation as well).</p>
		<p> We will explain the algorithm in detail below, but the problem with the researchers' implementation of it in MATLAB is that it runs extraordinarily slow. Most of the inefficiency is a result of MATLAB being a script language that is compiled during execution. It took over 3 hours to generate the image of Albert Einstein above, and takes even more time for darker images that require more lines. Moreover, they have implemented matrix operations extensively to improve on the execution time from the original version, using a gigantic sparce matrix to convert from the space of edges to the space of pixels. For a 256 pin circular canvas on a 512x512 pixel image, that is a 262,144 by 130,560 matrix (assuming 4 possible edges per pin pair). This makes the code incapable of running on any computer with less than 32 GB of RAM, and even on a computer that satisfied such hardware requirements it filled 100% of the available memory.</p>
		<p> <b>Thus our goal was to implement specialized solvers on the FPGA, and accelerate the computation of this greedy optimization problem.</b> Since Barton is making his hardware design open-source, this would contribute to allowing more people to build the full system without needing a high-end computer and a MATLAB license. We were successful in implementing a reduced version of the best algorithm from the paper that showed over 100x acceleration in finding the result. However, we were not able to fit the supersampling portion on the DE1-SoC's FPGA due to memory constraints. Our design is presented below as well as further steps needed to achieve an equivalent result to the MATLAB program.</p>
		<h2>High Level Design</h2>

		<h3>Rationale</h3>
		<p>As mentioned, we drew insipiration from Barton Dring's Youtube video <a href = https://www.youtube.com/watch?v=M1gXuKFspgY><i>A New Spin on String Art Machines</i></a>, and based much of our algorithm development on the excellent research paper <a href = https://www.cg.tuwien.ac.at/research/publications/2018/Birsak2018-SA/><i>String Art: Towards Computational Fabrication of String Images</i></a> by Michael Birsak, Florian Rist, Peter Wonka and Przemyslaw Musialski. </p>

		<h3>Background Math</h3>
		<h4>The Optimization Problem</h4>
		<center>
			<figure>
				<img src="./Images/edgepixel.png" alt="Edge to Pixel" style="width:400px">
				<figcaption>Fig.3 Strings (Edges) on the Canvas (Image from Paper)</figcaption>
			</figure>
		</center>
		<p>The original optimization problem is formulated in the following way by the authors of the paper: The input, y, represents all the pixels in the grascale image, each taking a decimal value in the range [0, 1] or a whole number value in [0, 255] if 8 bit depth is used. The output, x, represents a binary array for all the possible edges that can be drawn on the canvas. Note the binary assumption is important, meaning that an edge cannot be drawn twice. For simplicity we can assume that the input array is concatenated row-wise from the 2D image array. Then we assume a mapping function F that transforms from space of edges to the space of pixels, which is to say that it defines which pixels on the canvas correspond to a particular edge. Figure 3 shows this relationship well. There are two key algorithms used for discrete line drawing: Bresenham, which is binary, and Xiaolin Wu, which is weighted and anti-aliased. The optimization task can then be cast as the following:</p>
		<center>
			<figure>
				<img src="./Images/opt1.png" alt="equation 1" style="width:125px">
			</figure>
		</center>
		<p>Where the norm can take on a variety of forms. The first approach that the paper experimented with is minimizing the linear least squares difference, with A being the linear mapping from edges to pixels using Xiaolin Wu algorithm:</p>
		<center>
			<figure>
				<img src="./Images/opt2.png" alt="equation 2" style="width:125px">
			</figure>
		</center>
		<p>This quadratic function can be easily and efficiently solved if the number of pixels is greater than the number of unique edges. However, the result x is not constrained to the binary output that we need (can be larger than 1 or negative), so one way is to clamp the output to binary 0 or 1. A great deal of precision is lost in this step, and the image from the first approach is far from satisfactory (figure 4, c).</p>
		<center>
			<figure>
				<img src="./Images/fig3.png" alt="PaperFig3" style="width:800px">
				<figcaption>Fig.4 Results Comparison of Different Algorithms (Image from Paper with Our Comments)</figcaption>
			</figure>
		</center>
		<p>At this point the authors present two key characteristics that have a large impact on the quality of images: binary optmization and expressive range.</p> 
		<p>First, since the final image is formed by the binary process of either keeping or removing a possible edge, optimization must also adhere to it in order to retain accuracy. This means choosing binary optimization schemes instead of rounding unbounded results. Second, the image fidelity is mainly held back by the lack of expressive range of individual edges. Even if Xiaolin Wu is used instead of Bresenham for drawing edges, the pixels corresponding to a line easily accumulate values larger than 1 when intersected meaning pure black. This is problematic as the canvas will be strongly contrasted between pure white and pure black, and grayscale details of the original image get lost. It might be reasonable to think that such a problem will be solved by going to a higher dimensional space, by supersampling the original image and drawing on an equally large canvas. While it does match details much more closely, ie. figure 4 (g) vs. (f), it does not solve the fundamental problem of expressing intermediate tones.</p>
		<p>The real solution, which the paper used on the last 3 images, is to draw lines on the supersampled canvas, then downsample to enlarge expressive range of each big pixel, and perform the difference calculation in the lower dimension space. Figure 4 (h) is their result using a downsampled unclamped integer programming scheme (meaning the pixel values are not capped at 1 when calculating difference) running on the pre-existing GUROBI optimization library. It seems like the unclamped condition was necessary to use the library, and certainly not ideal as overlapping lines can enlarge errors mathematically while in reality the maximum darkness is 1. So the algorithm will not shade dark areas as much as it needs to. Figure 4 (i) is just double-checking their GUROBI implementation, while figure 4 (j) is their custom downsampled clamped integer gramming optimization.</p>
		<p>The clamped implementation is certainly better, as figure 4 (j) recreates dark areas with much higher fidelity. Below is the final optimization formulation, with the swiggle A being the supersampling matrix, C being the clamping operator, and D being the downsampling. The paper also talks about implementing a weighted importance map to accentuate facial features, but we can ignore that for our implementation.</p>
		<center>
			<figure>
				<img src="./Images/opt3.png" alt="equation 3" style="width:150px">
			</figure>
		</center>
		<p>Solving this requires a custom algorithm. The authors chose to implement a greedy approach, and to ensure optimality the addition and removal of edges are interchanged when one no longer reduces the difference. A more understandable version of the pseudo-code is shown below:</p>
		<center>
			<figure>
				<img src="./Images/opt4.png" alt="equation 4" style="height:125px">
			</figure>
		</center>
		<!--
	  <pre><b>Initial supersampled white canvas;
Initial stage add;
While (either add or remove stage still reduce difference with original image) do
	(Latched) add/remove one best edge for reducing downsampled difference with image, return reduced difference and new canvas;
	if (reduced difference is 0 or negative)
		Flip next stage to opposite;
	end
end</b></pre>
	  -->
	  <p>The latched add/remove state simply means that algorithm will repeat its last operation unless signaled to change when there is no longer reduction. Thus the optimization problem is complete.</p>

	  <h4>Bresenham's Algorithm</h4>

	  <p>We chose to implement Bresenham's algorithm in our design, the reasons of which will be explained later. Below is a pseudo-code for the most common version. The derivations are shown <a href = https://www.youtube.com/watch?v=RGB-wlatStc>here</a>. Note that for slope greater than 1, simply exchange the x and y inputs and also exchange the x and y outputs.</p>
	  <center>
		  <figure>
			  <img src="./Images/opt5.png" alt="equation 5" style="height:250px">
		  </figure>
	  </center>
	  <!--
	   <pre><b>Bresenham_Algo(x1, y1, x2, y2)
	o_x = x1;
	o_y = y1;
	dx = x2-x1;
	dy = y2-y1;
	P = 2dy-dx;
	While (o_x<=x2)
		Output pixel (o_x, o_y);
		o_x++;
		if (P<0)
			P = P+2dy;
		else
			P = P+2dy-2dx;
			o_y++;
									end
									end
									end</b></pre>
	   -->
	   <h3>Logical Structure</h3>
	   <p>While the optmization algorithm above may not be difficult to implement in other programming languages, on the FPGA data storage and access can be rather challenging. For the process outlined by the pseudo-code above, we need a large patch of RAM to store the active canvas, which will be written to in the add/remove stage and read from when downsampling/calculating difference. The downsampling result potentially needs its own memory block, but can be buffered in registers if the difference calculation is done on the fly. The original image will also be needed but not modified, so that can be stored in a ROM patch. In addition, since verilog does not come with math libraries, the calculation of the pin pixels would have to be done with a sine/cosine lookup table if done online. That will take up storage space and repeate unnecessary calculations in each iteration, so the better option is to precompute those and also store them in a ROM block. Lastly, for manufacturability the output has to be stored as well. So the overall logical structure will be similar to the diagram below, excluding any additional processing that the HPS side could perform.</p>
	   <center>
		   <figure>
			   <img src="./Images/logicalstructure.png" alt="Logical Structure" style="height:400px">
			   <figcaption>Fig.5 Logical Structure Block Diagram</figcaption>
		   </figure>
	   </center>

	   <h3>Hardware/Software Tradeoffs</h3>
	   <p>Our goal was to accelerate the solver process, so speed of execution was the first focus of the design. This means keeping as much memory as possible on the native FPGA hardware, as that allows for the lowest delay acess and highest bandwidth with the possibility of parallelism. However, since memory was never a bottleneck in previous labs, we did not realize the DE1-SoC was actually quite limited in this resource. There are only about 3900 Kbits available in M10K blocks and only about 307 Kbits available in MLAB blocks. The 1GB DDR3 external SDRAM only has 64MB available through Qsys, and the rest is managed by the HPS operating system meaning about 10 FPGA clock cycle access delays.</p>
	   <p>To put this into perspective, a 8x supersampled 512x512 image results in a 4096x4096 matrix, and assume that each pixel has 8 bits to store the canvas edge information. The canvas RAM alone represents 16MB of RAM, far more than all on chip resources combined. The original image is 512x512 with 8 bit pixel depth, so the ROM will occupy an additional 256KB. Pin position ROM is smaller with 12 bits for each coordinate (assuming 4096 pixel canvas), but two of those will be needed for simultaneous read. With the standard 256 pin frame, that is 1.5KB of ROM. Lastly, the best edge in each iteration needs to be stored as well, not just for manufacturability but also for the removal stage iteration. For easy processing and reduced storage space, we can store just the corresponding pin position pair indices (2x8 = 16 bits for 256 pins). The total size of this is rather tricky, as it really should be a dynamically managed memory that grows with the number of edges. From our simulation in MATLAB, we did not see more than 2000 edges being drawn, so 2048 appears to be an acceptable fixed memory length. This results in a 4KB block of RAM.</p>
	   <p>At this point it became obvious to us that the vanilla optimization algorithm as presented in the paper is unviable for implementation directly on our FPGA, purely due to memory constraints. The total needed memory would be 16MB + 256KB + 1.5KB + 4KB. Since we would like to have the system draw the edges in real time during the solving process, we did not want to touch the offchip SDRAM, as moving the Altera IP VGA Subsystem off the buffer could prove to be a challenge in itself. In addition, we needed simultaneous access to at least the image and canvas blocks, which would be rather complicated to convert to a serial process (and possible involve Qsys challenges) if SDRAM is used.</p>
	   <p><b>Thus we decided to implement a reduced version of the final optimization algorithm that can be fit in the on-chip resources. The main reduction would be to eliminate the supersampling, which also removes the need for downsampling. </b>This makes the canvas memory significantly smaller. Although the results will have similar problems as shown in some trial images of figure 4, it would show if this implementation can achieve acceleration at all. The laters steps of implementing larger storage could be done on this base algorithm, and the algorithmic improvements can then be easily made. A MATLAB version of this is <a href = https://github.com/SkookumAsFrig/StringArtOnFPGA/tree/master/Paper_MATLABCode/MATLAB_Time_Results/Example_Algo>linked here</a>, and the pseudo-code is shown below.</p>

	   <!--
	    <pre><b>Initial white canvas (512x512);
Initial stage add;
While (either add or remove stage still reduces difference with original image) do
	(Latched) add/remove one best edge for reducing difference with image (512x512), return reduced difference and new canvas;
	Record best edge and add/remove;
	Draw new canvas;
	if (reduced difference is 0 or negative)
		Flip next stage to opposite;
	end
end</b></pre>
	    -->
	    <center>
		    <figure>
			    <img src="./Images/opt6.png" alt="equation 6" style="height:150px">
		    </figure>
	    </center>
	    <h3>Patents/Copyrights</h3>
	    <p>There are no patents that we are aware of relating to this project. However, there have been previous work done on this topic in addition to the research paper that we extensively referenced. Artist <a href = http://artof01.com/vrellis/works/knit.html>Petros Vrellis</a> has written his own algorithm for hand production of the same type of string art, even for <a href = https://www.saatchiart.com/account/artworks/858823>colored versions</a>. He has also collaborated with a father and son duo of MIT professors to create the <a href = http://erikdemaine.org/fonts/stringart/>String Art Font</a>.</p>

	    <h2>Program/Hardware Design</h2>
	    <h3>Program Overview </h3>
	    <center>
		    <figure>
			    <img src="./Images/overallsystem.jpg" alt="Overall System" style="width:600px">
			    <figcaption>Fig.6 Overall System Block Diagram</figcaption>
		    </figure>
	    </center>
	    <h4>Qsys </h4>
	    <p>The Qsys interconnection of our design is quite simple. The bus master of HPS and output from vga DMA controller are connected to SDRAM for writing and reading the pixel value. The seven pio ports are set up for data communication between HPS and FPGA, including ready and valid signal, optimal pin pair, add or remove flag and finish signal. Following figures show the details of Qsys configuration.</p>
	    <center>
		    <figure>
			    <img src="./Images/OverallQsys.jpg" alt="Overall Qsys" style="width:800px">
			    <figcaption>Fig.7 Overall Qsys with PIO Configuration</figcaption>
		    </figure>
	    </center>
	    <center>
		    <figure>
			    <img src="./Images/VGASS.jpg" alt="VGA Subsystem" style="width:600px">
			    <figcaption>Fig.8 VGA Subsystem Qsys Configuration (Quartus IP)</figcaption>
		    </figure>
	    </center>
	    <h4>Verilog Solver</h4>
	    <p>The FPGA part of our system is mainly responsible for the whole process of searching the optimal string which would be added or removed on the canvas. It can be divided into two sections, control module and computation module. The control module is responsible for adjusting the calculation mode of computation one and interacting with the HPS, while the computation module is responsible for accumulating and outputting the error reduction of each string. The detail of two modules is discussed as follows.</p>
	    <center>
		    <figure>
			    <img src="./Images/rdy_val_interface.png" alt="rdy_val Interface" style="width:500px">
			    <figcaption>Fig.9 Control and Communication Signal Interface</figcaption>
		    </figure>
	    </center>
	    <p>First, we want to introduce some design principles adopted in our system. Considering the mobility and robustness of the system, a well-designed and general communication interface is necessary to improve the performance and handle the problem of communication between latency-sensitive modules. Therefore, we adopted the idea of rdy/val interface, which is demonstrated in figure 9 above. It can be seen as a handshake agreement between two modules and transaction would cross the interface only if source output is valid and sink input port is ready.   Even for the cross-time domain transactions like communication between HPS and FPGA, the whole system could stall waiting for the response from HPS side.  Another method we used in our system is finite state machine, which could help us to divide the whole process into several steps. Therefore we could implement the system incrementally, which is easier and more efficient.  In addition, the more complex the system is, the more control signals it has. However, these signals are responsible for different states. Finite state machine could help us manage and trace them better and make the system insensitive to the irrelevant control signals for certain stage.</p>
	    <center>
		    <figure>
			    <img src="./Images/Compute_FSM.png" alt="Compute State Machine" style="width:500px">
			    <figcaption>Fig.10 Compute Finite-State Machine</figcaption>
		    </figure>
	    </center>
	    <p>In terms of the detailed architecture of the computation module, as shown in figure 10, it contains three stages, including idle, work and output stages. In idle stage, the module will initialize the variables and waiting for the requests from control module. As soon as the request is valid, it would calculate the input arguments of bresenham algorithm in one cycle. For work stage, it has four modes to select. The module would calculate the error reduction when adding or removing a string in mode 1 and mode 3 respectively. And it would add or remove the optimal string in mode 2 and mode 4. In fact, the computation module contains two memory blocks, one ROM for reference image and one RAM for reconstructed image. Each cell in ROM stored the gray value of the corresponding pixel in the original image with 8 bits and each cell in RAM stored the count of strings covering each pixel with 4 bits. There is one thing to note that it is possible the maximum number of covering strings is out of the range of 4 bits. However, based on our MATLAB testing, the count value cannot decrease from 15 to 0 in remove stage. It is sufficient to use 4 bits to express, which is also the best we can do to fit in the DE1-SOC memory. What’s more, we need to carefully handle the latency of memory read and write, especially when updating the content of RAM block. We designed a memory address storage pipeline due to that we need to read and write back the content resulting in two cycles latency. In output stage, the module would export the results and wait for the ready signal of control module.</p>
	    <center>
		    <figure>
			    <img src="./Images/Ctrl_FSM.png" alt="Control State Machine" style="width:600px">
			    <figcaption>Fig.11 Control Finite-State Machine</figcaption>
		    </figure>
	    </center>
	    <p>As for control module, it follows the FSM illustrated in figure 11. It is an implementation of the greedy searching algorithm to reduce the error as much as possible. As mentioned in the paper, we need to jump back and forth between adding stage and removing stage. In adding stage,  the system searched for all the strings that could narrow the gap best up till now. In removing stage, the system would erased the over-evaluated strings. It also has two memory blocks, one ROM for pin position and one RAM for optimal pin pair. After reset states, in which the module would set the default value for all the signals, the module would enter add or remove states to complete the tasks described above. In this case, we should also pay attention to the latency of memory reading and computation module rdy/val interface. When the optimal pin pair indexes are obtained, the system would enter the update stage to store or remove the content in RAM block. When facing the problem of non consecutive memory after removing, we chose to set the corresponding value into 0, which was an invalid number for pin pair index. Although this method wasted some memory space, it saved the time of moving each element forward and accelerated the processing speed. Afterwards, it would wait for the response from HPS side to grab the results and draw on the screen. When it is found that no more required strings could be added or removed, the system would enter the status of completion.</p>
	    <h4>Memory</h4>

	    <p>Apart from two main modules in our system, memory blocks play an important role in storing the data. There are many methods to infer memory in the design,  but we directly used the template offered by Quartus software, which contains the verilog schematic for various memory behaviour. For DE1-Soc device, it offers three sources to synthesize the memory blocks, including M10K, MLAb and logic. Combining with the synthesis attribution, we can assign which source to synthesize certain module. There is one thing to mention that one memory block can only be synthesized by only one source, therefore, we need to optimize the management of resources to maximize the usage ratio of memory. In general, M10K block is preferred to store large consecutive data array with the volume of exponent of 2, while logic and MLAB are preferred to store small number of data with more flexibility. What’s more, comparing with MLAB, memory synthesized by logic is more time consuming and occupies the resources for other logic components. Considering the characteristics mentioned above, The ROM for reference image and RAM for reconstructed image are synthesized by M10K blocks, while the ROM for pixel position of pins and the RAM for added strings are synthesized by MLAB.</p>
	    <p>After obtaining the initialization file of memory from HPS side, we used the system task of $readmemh in initial block to initialize two ROMs in our design. The format is shown below. The first argument is the path of file and the second one is the memory block variable name.</p>
	    <center>
		    <p>$readmemh(filePath, mem) </p>
	    </center>
	    <p>As mentioned in high level tradeoffs, due to the sizable reduction in memory requirements when supersampling is removed, we were able to fit all 5 blocks of memory (4 different types) into hardware resources. The original image is still 512x512 with 8 bit pixel depth, and its ROM occupies 256KB. The canvas, however, is scaled down to only require 512x512 with 4 bit range, and its RAM occupies 128KB. Together with the image ROM they use up 100% of the M10K blocks (384KB). The two pin position ROM blocks and the edge RAM block are synthesized to use MLAB as mentioned above. The pin positions only require 9 bits for each coordinate now, so the total MLAB usage is around 1KB + 4KB from edge RAM block= 5KB. It is worth mentioning that we opted to use the parameterized module functionality of Verilog in constructing the different memory blocks. This way changes to the length and data width can be made easily where they are declared, and not require editing the memory file every time.</p>
	    <center>
		    <figure>
			    <img src="./Images/memory.png" alt="Parameterized Memory" style="width:600px">
			    <figcaption>Fig.12 Parameterized Memory Block</figcaption>
		    </figure>
	    </center>
	    <h4>Verilog VGA Graphics</h4>
	    <p>We used  <a href = http://people.ece.cornell.edu/land/courses/ece5760/DE1_SOC/HPS_peripherials/univ_pgm_computer.index.html>Video VGA 640x480 displayed from SDRAM, in 16-bit color</a>, from the ECE 5760 University Computer Graphics page as the base of the outermost module in our design. Since we wanted to use FPGA purely for computation, this was necessary to have the HPS control realtime drawing on the monitor. We had to make some modification as shown in the Qsys design, since the original on-chip SRAM is disconnected but takes up precious memory needed by the solver. That was removed entirely, and we interfaced the rest of the system with the DE1_SoC_Computer design.</p>

	    <h4>HPS </h4>
	    <p>In our system, the HPS component is responsible for precomputing the reference image and pin position of pixel. What’s more, it could draw the reconstructed image on the screen in real time to demonstrate how the system works explicitly. For image processing, we turned to the library of opencv, which is easy to be installed in linux environment and offers various functions. After reading the image as gray image, we would reverse it because it is easier to calculate when reconstructing the black area. The position of pins are assumed uniformly located along the  circumference. The data of image and pins’ position would be written into the file in hex format for FPGA to initialize the ROM. When FPGA is calculating, the HPS will wait for the valid data and draw the line added on the canvas. It is difficult to remove lines in real time since we cannot quickly calculate whether the pixel is covered by other strings or not. Therefore, we also had a hashset to track which one is removed. Finally, the HPS would redraw the image for performance comparison. </p>
	    <h3>RTL Diagrams </h3>
	    <h4>Outer Control Module</h4>
	    <center>
		    <figure>
			    <img src="./Images/RTL.png" alt="Add_Remove_Search" style="width:1000px">
			    <figcaption>Fig.13 Control Module Overall RTL Diagram</figcaption>
		    </figure>padding: 15px;
	    </center>
	    <center>
		    <figure>
			    <img src="./Images/pinpos12mem.png" alt="Pin Pose Mem" style="width:700px">
			    <figcaption>Fig.14 Pin Position Memory Connections in Control Module</figcaption>
		    </figure>
	    </center>
	    <center>
		    <figure>
			    <img src="./Images/pinpairmem.png" alt="Edge Mem" style="width:700px">
			    <figcaption>Fig.15 Edge Memory Connections in Control Module</figcaption>
		    </figure>
	    </center>
	    <h4>Inner Compute Module </h4>
	    <center>
		    <figure>
			    <img src="./Images/BhamSolver.png" alt="Bham_Solver" style="width:1000px">
			    <figcaption>Fig.16 Compute Module Overall RTL Diagram</figcaption>
		    </figure>
	    </center>
	    <center>
		    <figure>
			    <img src="./Images/bhamem.png" alt="Bham Mem" style="width:800px">
			    <figcaption>Fig.17 Image ROM and Canvas RAM Connections in Compute Module</figcaption>
		    </figure>
	    </center>
	    <center>
		    <figure>
			    <img src="./Images/statemachine.png" alt="Controller" style="width:700px">
			    <figcaption>Fig.18 Control State Machine in Compute Module</figcaption>
		    </figure>
	    </center>

	    <h2> Results </h2>
	    <h3> Testing </h3>
	    <p>Since this is a rather open ended project with many algorithmic approaches, we relied on the versatility of MATLAB to experiment with ideas. We mostly used the generated images to judge if a particular approach was acceptable, and ran it with multiple images on a workstation computer (since it was very slow). Then, after writing parts of the Verilog solver, we relied on ModelSim to verify the results against the same implementation in MATLAB. Below is a snippet of the testing of the controller together with the bresenham computation module, compared against our MATLAB script output.</p>
	    <center>
		    <figure>
			    <img src="./Images/modelsim.png" alt="ModelSim" style="width:1400px">
			    <figcaption>Fig.19 ModelSim Testing of Solver Module</figcaption>
		    </figure>
	    </center>
	    <center>
		    <figure>
			    <img src="./Images/matlab.png" alt="MATLAB" style="width:167px">
			    <figcaption>Fig.20 MATLAB Result of Solver Module</figcaption>
		    </figure>
	    </center>
	    <p> The first two lines of the ModelSim output is ready when the last line signal goes high, and represents the two pin position indices. Note that there exist a difference of 1 between both ModelSim outputs (151, 223), (163, 229) and the MATLAB results, due to the index differences of each programming language. MATLAB's indices begin at 1, hence the results are 1 larger than Verilog's which begins at 0.</p>
	    <h3> Final Results </h3> 
	    <div class="flex-container">
		    <figure>
			    <img src="./Images/adaori.png" alt="Original Image" style="height:400px">
			    <figcaption>Fig.21 Cutout of <i>Penitent Magdalene</i> by El Greco</figcaption>
		    </figure>
		    <figure>
			    <img src="./Images/ada.jpg" alt="Processed Image" style="height:400px">
			    <figcaption>Fig.22 FPGA Result</figcaption>
		    </figure>
	    </div>

	    <div class="flex-container">
		    <figure>
			    <img src="./Images/einstein_ori.png" alt="Original Image" style="height:400px">
			    <figcaption>Fig.23 Cutout of Albert Einstein's Famous Portrait</figcaption>
		    </figure>
		    <figure>
			    <img src="./Images/einsteindark.jpg" alt="Processed Image" style="height:400px">
			    <figcaption>Fig.24 FPGA Result</figcaption>
		    </figure>
	    </div>

	    <div class="flex-container">
		    <figure>
			    <img src="./Images/turingori.png" alt="Original Image" style="height:400px">
			    <figcaption>Fig.25 Cutout of Alan Turing</figcaption>
		    </figure>
		    <figure>
			    <img src="./Images/turing.jpg" alt="Processed Image" style="height:400px">
			    <figcaption>Fig.26 FPGA Result</figcaption>
		    </figure>
	    </div>
	    <div class="flex-container">
		    <figure>
			    <img src="./Images/peaceori.png" alt="Original Image" style="height:400px">
			    <figcaption>Fig.27 Peace Sign</figcaption>
		    </figure>
		    <figure>
			    <img src="./Images/peace.jpg" alt="Processed Image" style="height:400px">
			    <figcaption>Fig.28 FPGA Result</figcaption>
		    </figure>
	    </div>

	    <h3> Speed of Execution </h3>
	    <p> The following screenshots were obtained from running each of the above images.</p>
	    <div class="flex-container">
		    <figure>
			    <img src="./Images/ada.png" alt="ada time" style="height:700px">
			    <figcaption>Fig.29 Time of Execution for <i>Penitent Magdalene</i> Image (Fig. 22) </figcaption>
		    </figure>
		    <figure>
			    <img src="./Images/einstein1_darker.png" alt="einstein time" style="height:700px">
			    <figcaption>Fig.30 Time of Execution for Einstein Image (Fig. 24)</figcaption>
		    </figure>
	    </div>
	    <div class="flex-container">
		    <figure>
			    <img src="./Images/turing.png" alt="turing time" style="height:700px">
			    <figcaption>Fig.31 Time of Execution for Turing Image (Fig. 26)</figcaption>
		    </figure>
		    <figure>
			    <img src="./Images/peace.png" alt="peace time" style="height:700px">
			    <figcaption>Fig.32 Time of Execution for Peace Sign Image (Fig. 28)</figcaption>
		    </figure>
	    </div>
	    <p> We also ran some of the images above in MATLAB for comparison, with the same algorithm that we used for verification. However, not all of the MATLAB runs were completed, since they were taking upwards of 12 hours with our serial implementation. Since we had the MATLAB code occasionally print out running time and number of edges added, we can show the table below which compares their relative work efficiency, in edges added per second.</p>
	    <center>
		    <table style="width:800px">
			    <tr>
				    <th>Image</th>
				    <th>MATLAB Rate (Edges Per Second)</th>
				    <th>FPGA Rate (Edges Per Second)</th> 
				    <th>Acceleration (FPGA/MATLAB)</th>
			    </tr>
			    <tr>
				    <td><i>Penitent Magdalene</i></td>
				    <td>0.0286</td> 
				    <td>5.144</td>
				    <td>179.86</td>
			    </tr>
			    <tr>
				    <td>Einstein</td>
				    <td>0.0416</td> 
				    <td>5.182</td>
				    <td>124.57</td>
			    </tr>
			    <tr>
				    <td>Turing</td>
				    <td>0.0284</td> 
				    <td>5.108</td>
				    <td>179.86</td>
			    </tr>
		    </table>
	    </center>
	    <h3> Safety and Usability </h3>
	    <p> To </p>

	    <h2> Conclusions </h2>
	    <p>Looking back our expectations, the results of what we were able to accomplish exceeded our expectations for the class project: all sensors worked and were integrated together, the test sequence is nearly completely autonmous, and based on the contour maps we have seen from our few trials, the data collected seems reasonable and will be useful for future use by the Resistance Racing team. Further work we could do to improve our project even more is to have the test sequence able to loop back after changing the voltage supply. This way multiple trials can be run and stored on the same text file rather; as of now, the data from different trials must be manually concatenated in order to display all collected data on the same contour map. This can also be improved with the integration of the motor controller for the brushless system, since that way with a more complex sequence we would be able to do sweep with a large number of data points.</p>

	    <p>In addition, data processing in the microcontroller system can be improved, by playing around with different filters and zeroing algorithms. Using a better powersupply would also help with the data collection, since we were getting some inconsistent results due to noise in testing. </p>

	    <p>We must say a big thank you to Professor Land for believing in us and this project, even when other professors and lab technicians were telling us this was not possible.</p>

	    <h3>Intellectual Property Considerations</h3>
	    <p>The sources we used for inspiration and help were mainly public forums or programming sites such as matworks. We did base some of our code off of the examples provided on the ECE 4760 course website and looked at tutorials for how to go about using our <a href=https://www.reddit.com/r/arduino/comments/4lmb8z/i_made_a_cheap_torque_sensor_with_a_socket/> strain gauges</a> and <a href=https://www.youtube.com/watch?v=spnl7JInMXc>current sensor</a>. We cited all references used in Appendix F.</p>

	    <h3>Ethical Considerations</h3>
	    <p>During this project, we tried to maintain and follow the IEEE Code of Ethics by ensuring the safety of our project and seeking help from others. Due to the complexity of our mechanical system, one of main priorities was keeping the system safe. We built our system in a bottom-up fashion, integrating smaller modules together until everything was connected; as we did so, we continually added safety features that addressed potential dangers. For example, once we integrated the high power supplies into our system, we changed our wiring to keep high power sections separate and added wires designed to handle high current and high voltage to these subsystems. Additionally, we created a plastic shield for the rotating section of the mechanical setup.</p>

	    <p>Since we completed this project in collaboration with the Resistance Racing project team, we made sure to inform both Professor Bruce Land and Resistance Racing advisor Professor Joe Skovira of our intentions prior to beginning this project to avoid any potential conflicts of interest. Throughout this project, and course as well, we sought honest criticism of our ideas and advice from Professor Land and the teaching assistants of this course and other faculty in the Enginnering school including Professor Alan Zehnder and Liran Gazit. Additionally, we pulled information and inspiration from online and credited them in text and Appendix F of this document.</p>

	    <p>Lastly, we strove to report the results of our project in a honest and clear manner. The data we collected came directly from the sensors integrated in our system. The contour map was used to display the data in a meaningful way. </p>

	    <h3> Final Demonstration Video </h3>
	    <center>
		    <iframe width="560" height="315" src="https://www.youtube.com/embed/EXzGEKHN4d0" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>
	    </center> 
	    <h3>Appendix A</h3>
	    <p>The group approves this report for inclusion on the course website.</p>
	    <p>The group approves the video for inclusion on the course youtube channel.</p>

	    <h3>Appendix B -- System Schematic and Pins Used</h3>
	    <center>
		    <img src="./Images/high_level_diagram.png" alt="high level diagram" style="width:1000px;height:312px;"> 
	    </center>
	    <br>
	    <center>
		    <img src="./Images/pins.jpg" alt="high level diagram" style="width:230px;height:260px;"> 
	    </center>

	    <h3>Appendix C -- Bill of Materials</h3>

	    <p>Since this was done as a part of the Resistance Racing project team, most of the costs were handled by the team. And so the budget limit was removed as explained in the lab 5 webpage.</p>
	    <center>
		    <img src="./Images/BOM1.jpg" alt="mechanical setup, side view" style="width:750px;height:214px;"> 
	    </center>
	    <center>
		    <img src="./Images/BOM2.jpg" alt="mechanical setup, front view" style="width:750px;height:384px;"> 
	    </center>

	    <h3>Appendix D -- Task Delegation</h3>
	    <p>Tasks worked on by Aasta Gandhi: UART communication, current sensor calibration, contour map MATLAB code, test sequence code, photointerrupter/RPM code, code integration, wheatstone bridge/amplifier circuitry </p>
	    <p>Tasks worked on by Kowin Shi: design and manufacturing of mechanical setup, strain gauge mounting, software filters for sensors, high power wiring, digital potentiometer calibration code, wheatstone bridge/amplifier circuitry </p>
	    <p>Tasks worked on by Erika Yu: current sensor calibration, contour map MATLAB code, test sequence code, soldering of power rail circuitry, high power wiring, wheatstone bridge/amplifier circuitry </p>

	    <h3>Appendix E -- Commented Code</h3>
	    <a href=https://raw.githubusercontent.com/agandhi97/ECE4760_dyno/master/contour4760final.m> Matlab Code</a>
	    <a href=https://raw.githubusercontent.com/agandhi97/ECE4760_dyno/master/lab5_compile.c>Final C Code</a>

	    <h3>Appendix F -- References</h3>
	    <br><a href=http://www.ansys-blog.com/advanced-design-electric-motors/> ANSYS Blog for Motor Efficiency Map</a>
	    <br><a href=https://www.youtube.com/watch?v=spnl7JInMXc> Current Sensor Calibration Tutorial Video</a>
	    <br><a href= https://www.digikey.com/product-detail/en/analog-devices-inc/AD5231BRUZ10-REEL7/AD5231BRUZ10-REEL7CT-ND/3314098> Digital Potentiometer Datasheet</a>
	    <br><a href=https://www.reddit.com/r/arduino/comments/4lmb8z/i_made_a_cheap_torque_sensor_with_a_socket/> DIY Torque Sensor Using Arduino and Strain Gauges</a>
	    <br><a href=http://www.allegromicro.com/en/Products/Current-Sensor-ICs/Fifty-To-Two-Hundred-Amp-Integrated-Conductor-Sensor-ICs/ACS758.aspx> Hall Effect Current Sensor ACS758 Datasheet</a>
	    <br><a href=www.cs.cornell.edu/courses/cs1112/2017fa/files/Notes/egL18/L18post.pdf>CS1112 Lecture 18 Slides</a>
	    <br><a href=https://www.mathworks.com/matlabcentral/answers/355102-how-to-draw-efficiency-map-contour-of-a-motor> Matlab Efficiency Map Contour Example</a>
	    <br><a href=http://www.sensorland.com/HowPage002.html> Strain Gage Diagram</a>
	    <br><a href = https://www.sparkfun.com/products/9299> Photointerrupter Product Information</a>
	    <br><a href=https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html> Putty Download Link</a>
	    <br><a href= http://people.ece.cornell.edu/land/courses/ece4760/PIC32/Target_board/serial_expander_dac_tft/Serial_fprmatted_BRL4.c> UART Serial Communication Example Code</a> 
	    <br><a href=https://www.adafruit.com/product/954> UART to USB serial Cable Product Information</a>
	    <br><a href=https://notendur.hi.is/rol/EIIa/EIIa2000/Taekniblod/AN078%20Strain%20gauge%20measurements.PDF> National Instruments Guide on Strain Gages</a>
	    <br><a href=http://www.vishaypg.com/docs/11210/125tk.pdf> Vishay 125tk Data Sheet</a>
	    <br><a href=http://www.allegromicro.com/en/Products/Current-Sensor-ICs/Fifty-To-Two-Hundred-Amp-Integrated-Conductor-Sensor-ICs/ACS758.aspx> ACS758 Data</a>
	    <br><a href=http://www.ti.com/lit/ds/sbos078/sbos078.pdf> INA121 Datasheet</a>
	    <br><a href=http://www.dtic.mil/docs/citations/ADA577582> US Army Lab Paper on Small Motor Dyno</a>
	    <br><a href=http://www.bpesolutions.com/atechnical/ServoWire.Code.pdf> Servo Wire Code</a>
	    <br><a href=http://people.ece.cornell.edu/land/courses/ece4760/#links> Answers to Anything PIC32: SPI, ADC, PWM, Pinout Diagram</a>

	</body>
</html> 
